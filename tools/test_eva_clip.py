#!/usr/bin/env python3
"""
æ¸¬è©¦ EVA-CLIP åŠŸèƒ½
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from tools.embedding_processors.clip_image_processor import CLIPImageProcessor
from PIL import Image
import numpy as np

def test_clip_models():
    """æ¸¬è©¦ä¸åŒçš„ CLIP æ¨¡å‹"""
    print("ğŸ” æ¸¬è©¦ CLIP æ¨¡å‹...")
    
    # æ¸¬è©¦åœ–ç‰‡
    test_image = Image.new('RGB', (224, 224), color='red')
    
    # æ¸¬è©¦æ¨™æº– CLIP
    print("\nğŸ“· æ¸¬è©¦æ¨™æº– CLIP æ¨¡å‹...")
    try:
        processor = CLIPImageProcessor("clip-vit-large-patch14")
        embedding = processor.get_image_embedding(test_image)
        print(f"âœ… æ¨™æº– CLIP æˆåŠŸ - embedding å½¢ç‹€: {embedding.shape}")
        print(f"   ç¯„ä¾‹å€¼: {embedding[:5]}")
    except Exception as e:
        print(f"âŒ æ¨™æº– CLIP å¤±æ•—: {e}")
    
    # æ¸¬è©¦ EVA-CLIP (æœƒè‡ªå‹•å›é€€åˆ°æ¨™æº– CLIP)
    print("\nğŸš€ æ¸¬è©¦ EVA-CLIP æ¨¡å‹...")
    try:
        processor = CLIPImageProcessor("EVA02-CLIP-bigE-14-plus_s9B")
        embedding = processor.get_image_embedding(test_image)
        print(f"âœ… EVA-CLIP æˆåŠŸ - embedding å½¢ç‹€: {embedding.shape}")
        print(f"   ç¯„ä¾‹å€¼: {embedding[:5]}")
    except Exception as e:
        print(f"âŒ EVA-CLIP å¤±æ•—: {e}")
    
    # æ¸¬è©¦æ–‡å­— embedding
    print("\nğŸ“ æ¸¬è©¦æ–‡å­— embedding...")
    try:
        processor = CLIPImageProcessor("clip-vit-large-patch14")
        text_embedding = processor.get_text_embedding("a red car")
        print(f"âœ… æ–‡å­— embedding æˆåŠŸ - embedding å½¢ç‹€: {text_embedding.shape}")
        print(f"   ç¯„ä¾‹å€¼: {text_embedding[:5]}")
    except Exception as e:
        print(f"âŒ æ–‡å­— embedding å¤±æ•—: {e}")
    
    # æ¸¬è©¦ç›¸ä¼¼åº¦è¨ˆç®—
    print("\nğŸ”— æ¸¬è©¦ç›¸ä¼¼åº¦è¨ˆç®—...")
    try:
        processor = CLIPImageProcessor("clip-vit-large-patch14")
        similarity = processor.get_similarity(test_image, "a red car")
        print(f"âœ… ç›¸ä¼¼åº¦è¨ˆç®—æˆåŠŸ - åˆ†æ•¸: {similarity:.4f}")
    except Exception as e:
        print(f"âŒ ç›¸ä¼¼åº¦è¨ˆç®—å¤±æ•—: {e}")

def test_batch_processing():
    """æ¸¬è©¦æ‰¹æ¬¡è™•ç†"""
    print("\nğŸ”„ æ¸¬è©¦æ‰¹æ¬¡è™•ç†...")
    
    try:
        processor = CLIPImageProcessor("clip-vit-large-patch14")
        
        # å‰µå»ºå¤šå¼µæ¸¬è©¦åœ–ç‰‡
        images = [
            Image.new('RGB', (224, 224), color='red'),
            Image.new('RGB', (224, 224), color='blue'),
            Image.new('RGB', (224, 224), color='green')
        ]
        
        # æ‰¹æ¬¡è™•ç†
        embeddings = processor.batch_process_images(images)
        print(f"âœ… æ‰¹æ¬¡è™•ç†æˆåŠŸ - embeddings å½¢ç‹€: {embeddings.shape}")
        print(f"   ç¯„ä¾‹å€¼: {embeddings[0][:5]}")
        
    except Exception as e:
        print(f"âŒ æ‰¹æ¬¡è™•ç†å¤±æ•—: {e}")

if __name__ == "__main__":
    print("=" * 60)
    print("EVA-CLIP åŠŸèƒ½æ¸¬è©¦")
    print("=" * 60)
    
    test_clip_models()
    test_batch_processing()
    
    print("\n" + "=" * 60)
    print("æ¸¬è©¦å®Œæˆï¼")
    print("=" * 60)
